{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/question-generator/blob/main/data_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwJQYWpw0bKh"
      },
      "source": [
        "### Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB30UaQqzMvZ"
      },
      "outputs": [],
      "source": [
        "# SQuAD dataset\n",
        "!wget https://data.deepai.org/squad1.1.zip\n",
        "!unzip squad1.1.zip\n",
        "\n",
        "# SciQ dataset\n",
        "!wget https://ai2-public-datasets.s3.amazonaws.com/sciq/SciQ.zip\n",
        "!unzip SciQ.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install third party libraries"
      ],
      "metadata": {
        "id": "RlGShTJnFhVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers==4.1.1\n",
        "!pip3 install tokenizers==0.9.4\n",
        "!pip3 install sentencepiece==0.1.94"
      ],
      "metadata": {
        "id": "6tMD73PQfpHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9r7FuwB0bKk"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dnArgwcUzUso"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from transformers import T5Tokenizer\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzJ_kkvj0bKl"
      },
      "source": [
        "### Extract data from json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_json(filepath):\n",
        "  \"\"\"Load json file from storage.\n",
        "\n",
        "  Args:\n",
        "    filepath (str): Path of json file.\n",
        "\n",
        "  Returns:\n",
        "    list(dict(obj)): List of nested dictionaries.\n",
        "  \"\"\"\n",
        "  data = {}\n",
        "\n",
        "  with open(filepath) as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "JTy8CLImDnr5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***SQuAD***\n",
        "\n",
        "- SQuAD dataset doesn't contain null values, so, no need to check.\n",
        "- We are only interested in generating questions from simple answers. So answers with more than 5 words will be filtered out."
      ],
      "metadata": {
        "id": "mftNffwYGEVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_from_squad(data):\n",
        "  \"\"\"Extract data from SQuAD dataset.\n",
        "\n",
        "  Args:\n",
        "    data (list(dict(obj))): List of nested dictionaries.\n",
        "\n",
        "  Returns:\n",
        "    tuple(list(str), list(str)): tuple of lists of model input and output. \n",
        "  \"\"\"\n",
        "  contexts = []\n",
        "  questions = []\n",
        "  answers = []\n",
        "\n",
        "  for topic in data['data']:\n",
        "    for dict_set in topic['paragraphs']:\n",
        "      for qna_set in dict_set['qas']:\n",
        "        if is_short_answer(qna_set['answers'][0]['text'], 5):\n",
        "          contexts.append(f\"context: {dict_set['context']}\")\n",
        "          questions.append(f\"question: {qna_set['question']}\")\n",
        "          answers.append(f\"answer: {qna_set['answers'][0]['text']}\")\n",
        "\n",
        "  return contexts, questions, answers"
      ],
      "metadata": {
        "id": "VSbdKr83F7pg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***SciQ***\n",
        "\n",
        "- SCiQ dataset contains empty string for some values of `support` (mentioned in dataset readme.txt). So, that will be filtered out.\n",
        "- We are only interested in generating questions from simple answers. So answers with more than 5 words will be filtered out."
      ],
      "metadata": {
        "id": "L4p9xtIdGhxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_from_sciq(data):\n",
        "  \"\"\"Extract data from SciQ dataset.\n",
        "\n",
        "  Args:\n",
        "    data (list(dict(obj))): List of nested dictionaries.\n",
        "\n",
        "  Returns:\n",
        "    tuple(list(str), list(str)): tuple of lists of model input and output. \n",
        "  \"\"\"\n",
        "  contexts = []\n",
        "  questions = []\n",
        "  answers = []\n",
        "\n",
        "  for dict_set in data:\n",
        "    if dict_set['support'] == \"\":\n",
        "      continue\n",
        "    if is_short_answer(dict_set['correct_answer'], 5):\n",
        "      contexts.append(f\"context: {dict_set['support']}\")\n",
        "      questions.append(f\"question: {dict_set['question']}\")\n",
        "      answers.append(f\"answer: {dict_set['correct_answer']}\")\n",
        "\n",
        "  return contexts, questions, answers"
      ],
      "metadata": {
        "id": "HHpiOQSKC9bK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_short_answer(ans, threshold):\n",
        "  return len(ans.split()) <= threshold"
      ],
      "metadata": {
        "id": "EcPSX6I4WXaB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = parse_json('train-v1.1.json')\n",
        "squad_contexts, squad_questions, squad_answers = extract_from_squad(data)\n",
        "\n",
        "sciq_contexts = []\n",
        "sciq_questions = []\n",
        "sciq_answers = []\n",
        "\n",
        "for filename in ['train', 'test', 'valid']:\n",
        "  data = parse_json(f\"SciQ dataset-2 3/{filename}.json\")\n",
        "  contexts, questions, answers = extract_from_sciq(data)\n",
        "\n",
        "  sciq_contexts.extend(contexts)\n",
        "  sciq_questions.extend(questions)\n",
        "  sciq_answers.extend(answers)"
      ],
      "metadata": {
        "id": "-fJV1XwFKrPg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***SQuAD***\n",
        "- Total data: 87,599\n",
        "- Filtered data: 76,135\n",
        "\n",
        "\n",
        "***SciQ***\n",
        "- Total data: 13,679\n",
        "- Filtered data: 12,214"
      ],
      "metadata": {
        "id": "gRVEcDRVOyYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data visualization and reduction"
      ],
      "metadata": {
        "id": "C-Phi5_CFusJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter out any duplicate questions."
      ],
      "metadata": {
        "id": "LtFxGHVCYqRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squad_df = pd.DataFrame({'context': squad_contexts, 'question': squad_questions,\n",
        "                         'answer': squad_answers})\n",
        "sciq_df = pd.DataFrame({'context': sciq_contexts, 'question': sciq_questions, \n",
        "                        'answer': sciq_answers})\n",
        "\n",
        "squad_df.drop_duplicates(subset=['question'], ignore_index=True, inplace=True)\n",
        "sciq_df.drop_duplicates(subset=['question'], ignore_index=True, inplace=True)"
      ],
      "metadata": {
        "id": "wndYSKhIZpSZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***SQuAD***\n",
        "- Before: 76,135\n",
        "- After filtering out duplicates: 75,937\n",
        "\n",
        "\n",
        "***SciQ***\n",
        "- Before: 12,214\n",
        "- After filtering out duplicates: 12,133"
      ],
      "metadata": {
        "id": "DlBVR8ERal4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter out data with has exceeding tokens (than model input token size)"
      ],
      "metadata": {
        "id": "3Tc4nWaTh3ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ],
      "metadata": {
        "id": "XP92GWhybdNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### SAMPLE tokenization with padding ...\n",
        "encoding = t5_tokenizer.encode(sciq_df.loc[0,'context'], \n",
        "                               sciq_df.loc[0,'answer'], max_length=512, \n",
        "                               padding='max_length', truncation='only_first',\n",
        "                        add_special_tokens=True, return_attention_mask = True,\n",
        "                        return_tensors='pt')\n",
        "preds = [\n",
        "    t5_tokenizer.decode(\n",
        "        input_id, skip_special_tokens=False, clean_up_tokenization_spaces=False) \n",
        "    for input_id in encoding\n",
        "]\n",
        "\n",
        "\" \".join(preds)"
      ],
      "metadata": {
        "id": "4ahYtwc8eAUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_token_count(df, dataset):\n",
        "  \"\"\"Plot token count againts no of data.\n",
        "  \n",
        "  Args:\n",
        "    df (DataFrame): DataFrame of dataset that needs to plot.\n",
        "    dataset (str): Dataset name.\n",
        "  \"\"\"\n",
        "  source_token_count = []\n",
        "  target_token_count = []\n",
        "\n",
        "  for _, row in df.iterrows():\n",
        "    source_token_count.append(get_token_len(row['context'],\n",
        "                                                text_pair=row['answer']))\n",
        "    target_token_count.append(get_token_len(row['question']))\n",
        "\n",
        "  fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,10))\n",
        "  \n",
        "  sns.histplot(source_token_count, ax=ax1).set(title=f\"{dataset}-source-tokens\")\n",
        "  sns.histplot(target_token_count, ax=ax2).set(title=f\"{dataset}-target-tokens\")"
      ],
      "metadata": {
        "id": "aczVq9_tbBo8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_token_len(text, text_pair=None):\n",
        "  \"\"\"Get length of tokens\n",
        "\n",
        "  Args:\n",
        "    text (str): 1st input sequence.\n",
        "    text_pair (str): 2nd input sequence. Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    (int): Length of tokens.\n",
        "  \"\"\"\n",
        "\n",
        "  return len(t5_tokenizer.encode(text,text_pair))"
      ],
      "metadata": {
        "id": "9SDlEPVoiq_i"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_out_tokens(df, max_token_len, text, text_pair):\n",
        "  \"\"\"Delete rows which has data with exceeding token length.\n",
        "\n",
        "  Args:\n",
        "    df (DataFrame): Dataset that needs to be processed.\n",
        "    max_token_len (int): Maximum token length (For model input = 512).\n",
        "    text (str): 1st input sequence.\n",
        "    text_pair (str): 2nd input sequence.\n",
        "\n",
        "  Returns:\n",
        "    (DataFrame): Filtered dataset by 'filter_by' attribute\n",
        "  \"\"\"\n",
        "  df['not_exceeded'] = df.apply(\n",
        "      lambda x: len(t5_tokenizer.encode(x[text])) <= max_token_len, axis=1)\\\n",
        "   if text_pair == None else df.apply(lambda x: len(t5_tokenizer.encode(\n",
        "       x[text], x[text_pair])) <= max_token_len, axis=1)\n",
        "  df = df[df['not_exceeded']]\n",
        "  return df.drop(columns=['not_exceeded'])"
      ],
      "metadata": {
        "id": "YVipA1jOkgyG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_df_by_token_len(df, dataset, max_token_len, text, text_pair=None):\n",
        "  \"\"\"Filter dataset against model requirements.\n",
        "\n",
        "  Args:\n",
        "    df (DataFrame): Dataset that needs to be processed.\n",
        "    dataset (str): Dataset name.\n",
        "    max_token_len (int): Maximum token length (For model input = 512).\n",
        "    text (str): 1st input sequence.\n",
        "    text_pair (str): 2nd input sequence. Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    (DataFrame): Filtered dataset by 'filter_by' attribute\n",
        "  \"\"\"\n",
        "  print(f\"filter by {text}\")\n",
        "  print('Before filtering...')\n",
        "  plot_token_count(df, dataset)\n",
        "  df = filter_out_tokens(df, max_token_len, text, text_pair)\n",
        "  print('After filtering...')\n",
        "  plot_token_count(df, dataset)\n",
        "  return df"
      ],
      "metadata": {
        "id": "e2DcCwu28u4T"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***SciQ***"
      ],
      "metadata": {
        "id": "tpSlTj5QHMVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sciq_df = filter_df_by_token_len(sciq_df, 'SciQ', 512, 'context', 'answer')"
      ],
      "metadata": {
        "id": "13023vFiCRiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since most of 'target_text' token lengths are between 0-6x, filter out the outliers. (Used to set max out token length in Model training)\n",
        "\n",
        "Let's filtered out by 72.\n"
      ],
      "metadata": {
        "id": "B95oLby3HaEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sciq_df = filter_df_by_token_len(sciq_df, 'SciQ', 72, 'question')"
      ],
      "metadata": {
        "id": "zOYnVvePjI-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***SQuAD***"
      ],
      "metadata": {
        "id": "q4UC_NrwH82l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squad_df = filter_df_by_token_len(squad_df, 'SQuAD', 512, 'context', 'answer')"
      ],
      "metadata": {
        "id": "V1FSb2KCxp-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since most of 'target_text' token lengths are between 0-4x, filter out the outliers. (Used to set max out token length in Model training)\n",
        "\n",
        "Let's filtered out by 48."
      ],
      "metadata": {
        "id": "NpxxKCCoICNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> We aren't combining both dataset for training. Each one will be trained separately for different purpose. So, differ in max output length doesn't matter."
      ],
      "metadata": {
        "id": "FI0xl8ENIP93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squad_df = filter_df_by_token_len(squad_df, 'SQuAD', 48, 'question')"
      ],
      "metadata": {
        "id": "3eAjTolNEw9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***SQuAD***\n",
        "- Before: 75,937\n",
        "- After filtering out data w exceeding token lens: 75,683\n",
        "\n",
        "\n",
        "***SciQ***\n",
        "- Before: 12,133\n",
        "- After filtering out data w exceeding token lens: 11,964"
      ],
      "metadata": {
        "id": "rPMqCgHX6QCj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyKaYJnF0bKr"
      },
      "source": [
        "### Export as *.csv and upload to GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7g2Ab4aC9HT"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bMnlCw4DEXMA"
      },
      "outputs": [],
      "source": [
        "sciq_df.to_csv('SciQ-processed.csv', index=False)\n",
        "squad_df.to_csv('SQuAD-processed.csv', index=False)\n",
        "\n",
        "!mv SciQ-processed.csv SQuAD-processed.csv gdrive/MyDrive/mcq-gen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d_wu1TOorGGK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "squad-data-extraction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}