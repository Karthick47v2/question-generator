{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzM6nJJ2SlNs"
      },
      "outputs": [],
      "source": [
        "# SciQ dataset\n",
        "!wget https://ai2-public-datasets.s3.amazonaws.com/sciq/SciQ.zip\n",
        "!unzip SciQ.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH98ok22SqJD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extract data from json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtLlfbvoZeWk"
      },
      "outputs": [],
      "source": [
        "def parse_json(dataset):\n",
        "  \"\"\"Load and parse json data.\n",
        "\n",
        "  Extract context, question and answer information from json file.\n",
        "\n",
        "  Args:\n",
        "      dataset (str): Name of json file.\n",
        "  \"\"\"\n",
        "  data = {}\n",
        "\n",
        "  with open(f\"SciQ dataset-2 3/{dataset}.json\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "  for dict_set in data:\n",
        "    # there might be \"\" string in support --- mentioned in readme.txt\n",
        "    if dict_set['support'] != \"\":\n",
        "      source_text.append(f\"context: {dict_set['support']} answer: {dict_set['correct_answer']}\")\n",
        "      target_text.append(dict_set['question'])\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1V5ujT4ZWS1"
      },
      "outputs": [],
      "source": [
        "# dataframe containing 'source_text' and 'target_text' cols is the required format for SimpleT5 (used for training).\n",
        "source_text = []\n",
        "target_text = []\n",
        "\n",
        "for dataset in ['train', 'test', 'valid']:\n",
        "  parse_json(dataset)\n",
        "\n",
        "df = pd.DataFrame({'source_text': source_text, 'target_text': target_text})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrJeMw2QagqW"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Export as *.csv and upload to GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZRF51fua4bz",
        "outputId": "25514120-1f56-4f63-c939-4a388286677a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utJWbKF5a4z-"
      },
      "outputs": [],
      "source": [
        "!mv SciQ-processed.csv gdrive/MyDrive/mcq-gen\n",
        "df.to_csv('SciQ-processed.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sciq-data-extraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
