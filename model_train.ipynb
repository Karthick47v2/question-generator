{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYMYckZSXwmTAo2Nfn0lXG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/question-generator/blob/main/model_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ADD test\n",
        "## Add opt"
      ],
      "metadata": {
        "id": "FKrUy00DZL2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install 3rd party libraries"
      ],
      "metadata": {
        "id": "H_4LZBtWn9_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers==4.1.1\n",
        "!pip3 install pytorch-lightning==1.1.3\n",
        "!pip3 install tokenizers==0.9.4\n",
        "\n",
        "!pip install git+https://github.com/PyTorchLightning/lightning-bolts"
      ],
      "metadata": {
        "id": "tebaLpMeZcZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries\n",
        "\n",
        "> You ***may*** need to restart runtime after installing python packages. (If importing `pytorch_lightning` throws error)"
      ],
      "metadata": {
        "id": "Y0nXIohjoKIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import copy\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AdamW, T5ForConditionalGeneration, T5Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# set random state\n",
        "pl.seed_everything(42)"
      ],
      "metadata": {
        "id": "XmxtuwSvZxrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and split dataset"
      ],
      "metadata": {
        "id": "0d1k1uPls5Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfBBMKiYXfPu",
        "outputId": "ca265ae6-3607-4377-e689-d8a2fc0db1e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'sciq' ## squad or sciq\n",
        "\n",
        "df = pd.read_csv(f\"gdrive/MyDrive/mcq-gen/{'SQuAD' if dataset == 'squad' else 'SciQ'}-processed.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "U_62wakkXhiJ",
        "outputId": "62ee597f-56d9-473f-c29d-6104905c637e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8232b3dd09a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sciq'\u001b[0m \u001b[0;31m## squad or sciq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"gdrive/MyDrive/mcq-gen/{'SQuAD' if dataset == 'squad' else 'SciQ'}-processed.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)\n",
        "train_df.shape, test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dH_BAf4YGxM",
        "outputId": "3cdfbffc-148f-48ff-8c20-d7f5a515953b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8512, 2), (2128, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load base model"
      ],
      "metadata": {
        "id": "yZR2UJH1tPPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained('t5-base')"
      ],
      "metadata": {
        "id": "F5UcdYOVbAlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create dataset class inheriting Torch Dataset"
      ],
      "metadata": {
        "id": "0r6Zcckzx3fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuestionGenerationDataset(Dataset):\n",
        "  def __init__(self, tokenizer, data, max_in_len=512, max_out_len=96):\n",
        "    self.data = data\n",
        "    self.max_in_len = max_in_len\n",
        "    self.max_out_len = max_out_len\n",
        "    self.tokenizer = tokenizer\n",
        "    self.inputs = []\n",
        "    self.targets = []\n",
        "    self.__tokenize()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.inputs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
        "    target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
        "\n",
        "    src_mask = self.inputs[index][\"attention_mask\"].squeeze()\n",
        "    target_mask = self.targets[index][\"attention_mask\"].squeeze()\n",
        "    \n",
        "    labels = copy.deepcopy(target_ids)\n",
        "    labels[labels==0] = -100\n",
        "\n",
        "    return {\"source_ids\" : source_ids, \"source_mask\" : src_mask, \"target_ids\" : target_ids, \"target_mask\" : target_mask, \"labels\" : labels}\n",
        "\n",
        "  def __check_token_len(self, text, max):\n",
        "    test_encoding = self.tokenizer.encode_plus(\n",
        "                              text,\n",
        "                              truncation=False,\n",
        "                              return_tensors='pt'\n",
        "                              )\n",
        "    token_len = len(test_encoding['input_ids'][0])\n",
        "\n",
        "    return token_len > max\n",
        "\n",
        "\n",
        "  \n",
        "  def __tokenize(self):\n",
        "    for _, row in self.data.iterrows():\n",
        "      source_text, target_text = row['source_text'], row['target_text']\n",
        "\n",
        "      if self.__check_token_len(source_text, self.max_in_len):\n",
        "          continue\n",
        "      if self.__check_token_len(target_text, self.max_out_len):\n",
        "          continue     \n",
        "\n",
        "      tokenized_source = self.tokenizer.batch_encode_plus(\n",
        "                              [source_text],\n",
        "                              max_length=self.max_in_len,\n",
        "                              pad_to_max_length=True,\n",
        "                              return_tensors='pt'\n",
        "                              )\n",
        "      \n",
        "      tokenized_target = self.tokenizer.batch_encode_plus(\n",
        "                              [target_text],\n",
        "                              max_length=self.max_out_len,\n",
        "                              pad_to_max_length=True,\n",
        "                              return_tensors='pt'\n",
        "                              )\n",
        "      \n",
        "      self.inputs.append(tokenized_source)\n",
        "      self.targets.append(tokenized_input)"
      ],
      "metadata": {
        "id": "MbKYUsiCbCX-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = QuestionGenerationDataset(t5_tokenizer, train_df)\n",
        "validation_dataset = QuestionGenerationDataset(t5_tokenizer, test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7A0Lu00f6xn",
        "outputId": "ca5aa20b-c241-4b87-d57b-e6e42914e9e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***SQuAD (80-20 split)***\n",
        "\n",
        "***Train***\n",
        "\n",
        "Before: 70,079\n",
        "\n",
        "After filtering out data with exceeding tokens: 69,869\n",
        "\n",
        "***Validation***\n",
        "\n",
        "Before: 17,520\n",
        "\n",
        "After filtering out data with exceeding tokens: 17,467\n",
        "\n",
        "\n",
        "### ***SciQ (80-20 split)***\n",
        "\n",
        "***Train***\n",
        "\n",
        "Before: 8,512\n",
        "\n",
        "After filtering out data with exceeding tokens: 8,409\n",
        "\n",
        "***Validation***\n",
        "\n",
        "Before: 2,128\n",
        "\n",
        "After filtering out data with exceeding tokens: 2,092\n"
      ],
      "metadata": {
        "id": "tQmFLR0JiFlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create module class inheriting Python Lightning, LightningModule"
      ],
      "metadata": {
        "id": "6uh48jI1yXZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class T5FineTuner(pl.LightningModule):\n",
        "  def __init__(self, batch_size, t5model, t5tokenizer):\n",
        "    super(T5FineTuner, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.model = t5model\n",
        "    self.tokenizer = t5tokenizer\n",
        "\n",
        "  def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, \n",
        "              decoder_attention_mask=None, lm_labels=None):\n",
        "    outputs = self.model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        decoder_attention_mask=decoder_attention_mask,\n",
        "        labels=lm_labels,\n",
        "    )\n",
        "    return outputs\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    outputs = self.forward(\n",
        "        input_ids=batch['source_ids'],\n",
        "        attention_mask=batch['source_mask'],\n",
        "        decoder_input_ids=batch['target_ids'],\n",
        "        decoder_attention_mask=batch['target_mask'],\n",
        "        lm_labels=batch['labels']\n",
        "    )\n",
        "\n",
        "    loss = outputs[0]\n",
        "    self.log('train_loss',loss)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    outputs = self.forward(\n",
        "        input_ids=batch['source_ids'],\n",
        "        attention_mask=batch['source_mask'],\n",
        "        decoder_input_ids=batch['target_ids'],\n",
        "        decoder_attention_mask=batch['target_mask'],\n",
        "        lm_labels=batch['labels']\n",
        "    )\n",
        "\n",
        "    loss = outputs[0]\n",
        "    self.log('val_loss',loss, on_step=True, on_epoch=True, prog_bar=True, \n",
        "             logger=True)\n",
        "    return loss\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True,\n",
        "                      num_workers=4)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(validation_dataset, batch_size=self.batch_size,\n",
        "                      num_workers=4)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = AdamW(self.parameters(), lr=3e-4, eps=1e-8)\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "EcTRK_TP19fV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5FineTuner(8, t5_model, t5_tokenizer)\n",
        "trainer = pl.Trainer(max_epochs=1 ,gpus=1)\n",
        "trainer.fit(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "R6SnJSDY2SS5",
        "outputId": "f3ef5328-71e5-4466-b8b7-e6c7863eded2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:446: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
            "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MisconfigurationException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-410e8131f691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5FineTuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt5_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt5_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/argparse.py\u001b[0m in \u001b[0;36minsert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# all args were already moved to kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_env_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logger, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mamp_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamp_backend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mamp_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamp_level\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0mplugins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger_connector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoggerConnector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerator_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_choose_gpu_accelerator_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_parallel_devices_and_init_accelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# 3. Instantiate ClusterEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36m_set_parallel_devices_and_init_accelerator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             ]\n\u001b[1;32m    529\u001b[0m             raise MisconfigurationException(\n\u001b[0;32m--> 530\u001b[0;31m                 \u001b[0;34mf\"{self.accelerator.__class__.__qualname__} can not run on your system\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m                 \u001b[0;34m\" since the accelerator is not available. The following accelerator(s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0;34m\" is available and can be passed into `accelerator` argument of\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMisconfigurationException\u001b[0m: CUDAAccelerator can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu']."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-DJmjXlZ2etl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}