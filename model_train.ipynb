{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJYtsQbjG7lOyIbHAeCWCm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/question-generator/blob/main/model_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install 3rd party libraries"
      ],
      "metadata": {
        "id": "H_4LZBtWn9_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pytorch-lightning==1.7.0\n",
        " # newwer version not works with FastT5 (for ONNX conversion)\n",
        "!pip3 install transformers==4.1.1\n",
        "!pip3 install tokenizers==0.9.4\n",
        "!pip3 install sentencepiece==0.1.94"
      ],
      "metadata": {
        "id": "tebaLpMeZcZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries\n",
        "\n",
        "> You ***may*** need to restart runtime after installing python packages. (If importing `pytorch_lightning` throws error)"
      ],
      "metadata": {
        "id": "Y0nXIohjoKIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AdamW, T5ForConditionalGeneration, T5Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "pl.seed_everything(42)"
      ],
      "metadata": {
        "id": "XmxtuwSvZxrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and split dataset"
      ],
      "metadata": {
        "id": "0d1k1uPls5Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "zfBBMKiYXfPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'sciq' ## squad or sciq\n",
        "\n",
        "df = pd.read_csv(f\"gdrive/MyDrive/mcq-gen/{'SQuAD' if dataset == 'squad' else 'SciQ'}-processed.csv\")"
      ],
      "metadata": {
        "id": "U_62wakkXhiJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, validation_df = train_test_split(df, test_size=0.1, shuffle=True)\n",
        "validation_df, test_df = train_test_split(validation_df, test_size=0.4)\n",
        "train_df.shape, validation_df.shape, test_df.shape"
      ],
      "metadata": {
        "id": "xOANNkr0In1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load base model"
      ],
      "metadata": {
        "id": "yZR2UJH1tPPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ],
      "metadata": {
        "id": "F5UcdYOVbAlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset code\n"
      ],
      "metadata": {
        "id": "0r6Zcckzx3fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "  def __init__(self, tokenizer, data, max_out_len, max_in_len=512):\n",
        "    self.data = data\n",
        "    self.max_in_len = max_in_len\n",
        "    self.max_out_len = max_out_len\n",
        "    self.tokenizer = tokenizer\n",
        "    self.inputs = []\n",
        "    self.targets = []\n",
        "    self.__tokenize()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    labels = self.targets[index][\"input_ids\"]\n",
        "    labels[labels==0] = -100\n",
        "\n",
        "    return {'context': self.data.iloc[index]['context'], \n",
        "            'answer': self.data.iloc[index]['answer'], \n",
        "            'question': self.data.iloc[index]['question'],\n",
        "            'input_ids': self.inputs[index][\"input_ids\"].flatten(),\n",
        "            'attention_mask': self.inputs[index][\"attention_mask\"].flatten(),\n",
        "            'labels': labels.flatten(),\n",
        "            'labels_attention_mask': \n",
        "            self.targets[index][\"attention_mask\"].flatten()\n",
        "            }\n",
        "\n",
        "  def __tokenize(self):\n",
        "    for _, row in self.data.iterrows():\n",
        "      context, answer, question = row['context'], row['answer'], row['question']\n",
        "\n",
        "      source_encoding = self.tokenizer(\n",
        "                              context, answer,\n",
        "                              max_length=self.max_in_len,\n",
        "                              padding='max_length',\n",
        "                              truncation='only_first',\n",
        "                              return_attention_mask=True,\n",
        "                              add_special_tokens=True,\n",
        "                              return_tensors='pt'\n",
        "                              )\n",
        "      \n",
        "      target_encoding = self.tokenizer(\n",
        "                              question,\n",
        "                              max_length=self.max_out_len,\n",
        "                              padding='max_length',\n",
        "                              truncation=True,\n",
        "                              return_attention_mask=True,\n",
        "                              add_special_tokens=True,\n",
        "                              return_tensors='pt'\n",
        "                              )\n",
        "      \n",
        "      self.inputs.append(source_encoding)\n",
        "      self.targets.append(target_encoding)"
      ],
      "metadata": {
        "id": "MbKYUsiCbCX-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataModule(pl.LightningDataModule):\n",
        "  def __init__(self, train_df, validation_df, test_df, tokenizer, batch_size, \n",
        "               max_out_len, max_in_len=512):\n",
        "    super().__init__()\n",
        "    self.train_df = train_df\n",
        "    self.validation_df = validation_df\n",
        "    self.test_df = test_df\n",
        "    self.tokenizer = tokenizer\n",
        "    self.batch_size = batch_size\n",
        "    self.max_in_len = max_in_len\n",
        "    self.max_out_len = max_out_len\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "    self.train_dataset = QADataset(self.tokenizer, self.train_df, \n",
        "                                   self.max_out_len, self.max_in_len)\n",
        "    self.validation_dataset = QADataset(self.tokenizer, self.validation_df, \n",
        "                                        self.max_out_len, self.max_in_len)\n",
        "    self.test_dataset = QADataset(self.tokenizer, self.test_df, \n",
        "                                  self.max_out_len, self.max_in_len)\n",
        "    \n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_dataset, batch_size=self.batch_size, \n",
        "                      shuffle=True, num_workers=os.cpu_count())\n",
        "    \n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.validation_dataset, batch_size=2, \n",
        "                      num_workers=os.cpu_count())\n",
        "    \n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.test_dataset, batch_size=2,\n",
        "                      num_workers=os.cpu_count())"
      ],
      "metadata": {
        "id": "2EjS0J3UI5Xl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training code"
      ],
      "metadata": {
        "id": "6uh48jI1yXZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QAModel(pl.LightningModule):\n",
        "  def __init__(self, learning_rate=None):\n",
        "    super().__init__()\n",
        "    self.model = T5ForConditionalGeneration.from_pretrained('t5-base', \n",
        "                                                            return_dict=True)\n",
        "    self.lr = learning_rate\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, decoder_attention_mask, \n",
        "              labels=None):\n",
        "    outputs = self.model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        decoder_attention_mask=decoder_attention_mask,\n",
        "        labels=labels,\n",
        "    )\n",
        "    return outputs.loss, outputs.logits\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    \n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    labels_attention_mask = batch['labels_attention_mask']\n",
        "    labels = batch['labels']\n",
        "\n",
        "    loss, outputs = self(input_ids, attention_mask, labels_attention_mask,\n",
        "                         labels)\n",
        "\n",
        "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    labels_attention_mask = batch['labels_attention_mask']\n",
        "    labels = batch['labels']\n",
        "\n",
        "    loss, outputs = self(input_ids, attention_mask, labels_attention_mask,\n",
        "                         labels)\n",
        "\n",
        "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    labels_attention_mask = batch['labels_attention_mask']\n",
        "    labels = batch['labels']\n",
        "\n",
        "    loss, outputs = self(input_ids, attention_mask, labels_attention_mask,\n",
        "                         labels)\n",
        "\n",
        "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return AdamW(self.parameters(), lr=self.lr, eps=1e-8)"
      ],
      "metadata": {
        "id": "EcTRK_TP19fV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "N_EPOCHS = 3\n",
        "MAX_LR = 1e-2"
      ],
      "metadata": {
        "id": "0OUk72deQ8uE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find best LR"
      ],
      "metadata": {
        "id": "lGsOLZshRKwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_module = QADataModule(train_df, validation_df, test_df, t5_tokenizer, BATCH_SIZE, 72) # 48 / 72\n",
        "data_module.setup()"
      ],
      "metadata": {
        "id": "jXmX7J6DQ3Ak"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = QAModel(learning_rate = MAX_LR)\n",
        "trainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=20)"
      ],
      "metadata": {
        "id": "SmSAa5egF4tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_finder = trainer.tuner.lr_find(model, data_module, max_lr=MAX_LR)"
      ],
      "metadata": {
        "id": "iiTRPbQXGRVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = lr_finder.plot(suggest=True)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "veMkbQLyGueO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = lr_finder.suggestion()\n",
        "print(lr)"
      ],
      "metadata": {
        "id": "4pexpFS2G9Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***SciQ***\n",
        "\n",
        "Best lr ~ 0.000105"
      ],
      "metadata": {
        "id": "a2hyc07BS1c8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "Yz5TO7AjR4Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./lightning_logs"
      ],
      "metadata": {
        "id": "8aqM58uMGQ64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    dirpath=\"checkpoints\",\n",
        "    filename=\"model-{epoch:02d}-{val_loss:.2f}\",\n",
        "    save_top_k=1,\n",
        "    verbose=True,\n",
        "    mode=\"min\",\n",
        ")\n",
        "\n",
        "logger = pl.loggers.TensorBoardLogger('lightning_logs', name='SciQ-T5')"
      ],
      "metadata": {
        "id": "Id6CbeXWImmU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_module = QADataModule(train_df, validation_df, test_df, t5_tokenizer, \n",
        "                           BATCH_SIZE, 72) # 48 -squad / 72 - sciq\n",
        "data_module.setup()\n",
        "\n",
        "model = QAModel(learning_rate = lr)\n",
        "\n",
        "trainer = pl.Trainer(callbacks=[checkpoint_callback],\n",
        "                     max_epochs=N_EPOCHS, \n",
        "                     accelerator='gpu', \n",
        "                     devices=1,\n",
        "                     enable_progress_bar=True, \n",
        "                     logger=logger,\n",
        "                     precision= 32)"
      ],
      "metadata": {
        "id": "wbmON8IWMwnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, data_module)"
      ],
      "metadata": {
        "id": "bt8llpKoFQ_v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}