{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/question-generator/blob/main/model_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_4LZBtWn9_m"
      },
      "source": [
        "### Install 3rd party libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tebaLpMeZcZi"
      },
      "outputs": [],
      "source": [
        "!pip3 install pytorch-lightning == 1.7.0\n",
        "# newwer version not works with FastT5 (for ONNX conversion)\n",
        "!pip3 install transformers == 4.1.1\n",
        "!pip3 install tokenizers == 0.9.4\n",
        "!pip3 install sentencepiece == 0.1.94\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0nXIohjoKIe"
      },
      "source": [
        "### Import libraries\n",
        "\n",
        "> You **_may_** need to restart runtime after installing python packages. (If importing `pytorch_lightning` throws error)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmxtuwSvZxrH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AdamW, T5ForConditionalGeneration, T5Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "pl.seed_everything(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d1k1uPls5Yt"
      },
      "source": [
        "### Load and split dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfBBMKiYXfPu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U_62wakkXhiJ"
      },
      "outputs": [],
      "source": [
        "dataset = 'sciq'  # squad or sciq\n",
        "\n",
        "df = pd.read_csv(\n",
        "    f\"gdrive/MyDrive/mcq-gen/{'SQuAD' if dataset == 'squad' else 'SciQ'}-processed.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOANNkr0In1I"
      },
      "outputs": [],
      "source": [
        "train_df, validation_df = train_test_split(df, test_size=0.1, shuffle=True)\n",
        "validation_df, test_df = train_test_split(validation_df, test_size=0.4)\n",
        "train_df.shape, validation_df.shape, test_df.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZR2UJH1tPPJ"
      },
      "source": [
        "### Load base model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5UcdYOVbAlu"
      },
      "outputs": [],
      "source": [
        "t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r6Zcckzx3fl"
      },
      "source": [
        "### Dataset code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MbKYUsiCbCX-"
      },
      "outputs": [],
      "source": [
        "class QADataset(Dataset):\n",
        "    def __init__(self, tokenizer, data, max_out_len, max_in_len=512):\n",
        "        self.data = data\n",
        "        self.max_in_len = max_in_len\n",
        "        self.max_out_len = max_out_len\n",
        "        self.tokenizer = tokenizer\n",
        "        self.inputs = []\n",
        "        self.targets = []\n",
        "        self.__tokenize()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        labels = self.targets[index][\"input_ids\"]\n",
        "        labels[labels == 0] = -100\n",
        "\n",
        "        return {'context': self.data.iloc[index]['context'],\n",
        "                'answer': self.data.iloc[index]['answer'],\n",
        "                'question': self.data.iloc[index]['question'],\n",
        "                'input_ids': self.inputs[index][\"input_ids\"].flatten(),\n",
        "                'attention_mask': self.inputs[index][\"attention_mask\"].flatten(),\n",
        "                'labels': labels.flatten(),\n",
        "                'labels_attention_mask': self.targets[index][\"attention_mask\"].flatten()\n",
        "                }\n",
        "\n",
        "    def __tokenize(self):\n",
        "        for _, row in self.data.iterrows():\n",
        "            context, answer, question = row['context'], row['answer'], row['question']\n",
        "\n",
        "            source_encoding = self.tokenizer(\n",
        "                context, answer,\n",
        "                max_length=self.max_in_len,\n",
        "                padding='max_length',\n",
        "                truncation='only_first',\n",
        "                return_attention_mask=True,\n",
        "                add_special_tokens=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            target_encoding = self.tokenizer(\n",
        "                question,\n",
        "                max_length=self.max_out_len,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_attention_mask=True,\n",
        "                add_special_tokens=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            self.inputs.append(source_encoding)\n",
        "            self.targets.append(target_encoding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2EjS0J3UI5Xl"
      },
      "outputs": [],
      "source": [
        "class QADataModule(pl.LightningDataModule):\n",
        "    def __init__(self, train_df, validation_df, test_df, tokenizer, batch_size, max_out_len,\n",
        "                 max_in_len=512):\n",
        "        super().__init__()\n",
        "        self.train_df = train_df\n",
        "        self.validation_df = validation_df\n",
        "        self.test_df = test_df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "        self.max_in_len = max_in_len\n",
        "        self.max_out_len = max_out_len\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = QADataset(self.tokenizer,\n",
        "                                       self.train_df,\n",
        "                                       self.max_out_len,\n",
        "                                       self.max_in_len)\n",
        "        self.validation_dataset = QADataset(self.tokenizer,\n",
        "                                            self.validation_df,\n",
        "                                            self.max_out_len,\n",
        "                                            self.max_in_len)\n",
        "        self.test_dataset = QADataset(self.tokenizer,\n",
        "                                      self.test_df,\n",
        "                                      self.max_out_len,\n",
        "                                      self.max_in_len)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size,\n",
        "                          shuffle=True, num_workers=os.cpu_count())\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.validation_dataset, batch_size=2, num_workers=os.cpu_count())\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=2,  num_workers=os.cpu_count())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uh48jI1yXZn"
      },
      "source": [
        "### Model training code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EcTRK_TP19fV"
      },
      "outputs": [],
      "source": [
        "class QAModel(pl.LightningModule):\n",
        "    def __init__(self, learning_rate=None):\n",
        "        super().__init__()\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(\n",
        "            't5-base', return_dict=True)\n",
        "        self.lr = learning_rate\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, decoder_attention_mask, labels=None):\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "        return outputs.loss, outputs.logits\n",
        "\n",
        "    def step(self, batch, step):\n",
        "\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels_attention_mask = batch['labels_attention_mask']\n",
        "        labels = batch['labels']\n",
        "\n",
        "        loss, outputs = self(input_ids, attention_mask, labels_attention_mask,\n",
        "                             labels)\n",
        "\n",
        "        self.log(f\"{step}_loss\", loss, prog_bar=True, logger=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.step(batch, 'train')\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        return self.step(batch, 'val')\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "\n",
        "        return self.step(batch, 'test')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return AdamW(self.parameters(), lr=self.lr, eps=1e-8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0OUk72deQ8uE"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 8\n",
        "N_EPOCHS = 3\n",
        "MAX_LR = 1e-2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGsOLZshRKwj"
      },
      "source": [
        "### Find best LR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jXmX7J6DQ3Ak"
      },
      "outputs": [],
      "source": [
        "data_module = QADataModule(train_df, validation_df,\n",
        "                           test_df, t5_tokenizer, BATCH_SIZE, 72)  # 48 / 72\n",
        "data_module.setup()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmSAa5egF4tR"
      },
      "outputs": [],
      "source": [
        "model = QAModel(learning_rate=MAX_LR)\n",
        "trainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiTRPbQXGRVQ"
      },
      "outputs": [],
      "source": [
        "lr_finder = trainer.tuner.lr_find(model, data_module, max_lr=MAX_LR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veMkbQLyGueO"
      },
      "outputs": [],
      "source": [
        "fig = lr_finder.plot(suggest=True)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pexpFS2G9Ki"
      },
      "outputs": [],
      "source": [
        "lr = lr_finder.suggestion()\n",
        "print(lr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz5TO7AjR4Gq"
      },
      "source": [
        "### Train model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aqM58uMGQ64"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard - -logdir ./lightning_logs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Id6CbeXWImmU"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    dirpath=\"checkpoints\",\n",
        "    filename=\"model-{epoch:02d}-{val_loss:.2f}\",\n",
        "    save_top_k=1,\n",
        "    verbose=True,\n",
        "    mode=\"min\",\n",
        ")\n",
        "\n",
        "logger = pl.loggers.TensorBoardLogger('lightning_logs', name='SciQ-T5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbmON8IWMwnB"
      },
      "outputs": [],
      "source": [
        "data_module = QADataModule(train_df, validation_df, test_df, t5_tokenizer,\n",
        "                           BATCH_SIZE, 72)  # 48 -squad / 72 - sciq\n",
        "data_module.setup()\n",
        "\n",
        "model = QAModel(learning_rate=lr)\n",
        "\n",
        "trainer = pl.Trainer(callbacks=[checkpoint_callback],\n",
        "                     max_epochs=N_EPOCHS,\n",
        "                     accelerator='gpu',\n",
        "                     devices=1,\n",
        "                     enable_progress_bar=True,\n",
        "                     logger=logger,\n",
        "                     precision=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt8llpKoFQ_v"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model, data_module)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOJYtsQbjG7lOyIbHAeCWCm",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "model_train.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
